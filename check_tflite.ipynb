{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='tflite_models/mobv3_small_head_quan.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import skimage.draw\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_dir = Path('data/test')\n",
    "vid_path = vid_dir.iterdir().__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_size = (640,480)\n",
    "original_hw = (original_size[1],original_size[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.get_tensor_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_head(interpreter, original_frame):\n",
    "    total_start = time.time()\n",
    "    original_hw = original_frame.shape[:2]\n",
    "\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    target_size = tuple(input_details['shape'][2:0:-1])\n",
    "    resized_frame = cv2.resize(original_frame, dsize=target_size)[...,2::-1]\n",
    "    resized_frame = resized_frame[np.newaxis,...]\n",
    "\n",
    "    invoke_start = time.time()\n",
    "    input_idx = input_details['index']\n",
    "    interpreter.set_tensor(input_idx, resized_frame)\n",
    "\n",
    "    interpreter.invoke()\n",
    "\n",
    "    output_idx = interpreter.get_output_details()[0]['index']\n",
    "    invoke_end = time.time()\n",
    "    hm = np.squeeze(interpreter.get_tensor(output_idx))\n",
    "    \n",
    "    pos = np.unravel_index(hm.flatten().argmax(),hm.shape)\n",
    "    pos = np.multiply(pos, np.divide(original_hw,hm.shape)).astype(np.int)\n",
    "    rr,cc = skimage.draw.disk(pos,10, shape=original_hw)\n",
    "    original_frame[rr, cc] = [0,255,0]\n",
    "    return original_frame, invoke_end-invoke_start, time.time()-total_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(str(vid_path))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "frames = []\n",
    "drawn_frames =[]\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        frames.append(frame)\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "total_time_acc = 0\n",
    "invoke_time_acc = 0\n",
    "print('invoking')\n",
    "for frame in tqdm(frames[:200]):\n",
    "    drawn_frame, invoke_time, total_time = draw_head(interpreter, frame)\n",
    "    total_time_acc += total_time\n",
    "    invoke_time_acc += invoke_time\n",
    "    drawn_frames.append(drawn_frame)\n",
    "print(f'total time: {total_time_acc}')\n",
    "print(f'invoke time: {invoke_time_acc}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('writing')\n",
    "writer = cv2.VideoWriter('results/tflite_result.mp4',fourcc,30, original_size)\n",
    "for df in tqdm(drawn_frames):\n",
    "    writer.write(df[...,2::-1])\n",
    "writer.release()\n"
   ]
  }
 ]
}